\documentclass[a4paper,10pt]{article}
\usepackage[margin=0.5in]{geometry}
\usepackage{amsthm}
\usepackage[latin1]{inputenc}
%\usepackage[utf8]{inputenc}
%\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{float}
%\usepackage{amssymb}
\usepackage{fancyvrb}
\usepackage{indentfirst}
\usepackage{array}
\usepackage{graphicx}
\usepackage[round]{natbib}
\usepackage{array}
\theoremstyle{plain}
\usepackage{color}
\usepackage[boxed,commentsnumbered]{algorithm2e}
\newtheorem{theo}{Theorem}
\newtheorem{defn}{Definition}


\newcommand{\argmin}{\arg\!\min}
\newcommand{\argmax}{\arg\!\max}

\begin{document}
\author{Ieltzu Irazu, Mikel De Velasco Y María Inés Fernandez}
\pagenumbering{arabic}
\title{Práctica 6}

\author{\thanks{}}
\date{\today}
\maketitle

\section{Introducción:}
\subsection{Exposición de la práctica:}
En la práctica presentada se nos pide implementar el algoritmo K-Means para el conjunto de datos colon.arff. Para ello hemos desarrollado nuestro código en el lenguaje de programación Java y después hemos creado nuestro ejecutador .jar. Además hemos desarrollado este documento para plasmar las partes más importantes de la práctica.

\subsection{Objetivos:}
Los objetivos son claros; conseguir un algoritmo eficiente y efectivo para clusterizar un conjunto de datos del que no se sabe la clase. El código que hemos desarrollado no es dependiente a un solo conjunto de datos,ya que es posible utilizarlo en más de un conjunto de datos.

Como hemos recibido el archivo colon.arff para desarrollar la práctica vamos a analizar el archivo para ver su contenido. En el archivo de datos podemos encontrar 2000 variables predictoras. No tiene clase. Como son tantas variables nos limitaremos a decir que todas ellas son de tipo numérico, por lo tanto no habrá que discretizar ninguna variable y tampoco habrá que eliminar ninguna para poder implementar el algoritmo K-Means, ya que este solamente acepta variables de este tipo.

Para clusterizar nuestras instancias vamos a aplicar distintos grupos y haremos mediciones. Empezaremos dándole entrada del parámetro k a valor 2, el cual nos dice que cantidad de grupos vamos a tener para clusterizar las instancias. Una vez calculadas las particiones de datos calcularemos las métricas SSE y Silhouette para evaluarlo. 

\section{Pseudocódigo del algoritmo:}

\begin{algorithm}[H] 
\caption{JRip} 
\SetKwInOut{Input}{entrada} 
\SetKwInOut{Output}{salida}
\Input{Secuencia$_1,...,$ secuencia$_n$.} 
\Output{RuleSet} 
\While{$D_{Pos} = D_{Grow - Pos} \cup D_{Prune - Pos} \neq \emptyset$}{
	 \tcp*[r]{Construir una nueva regla}
	 Dividir $D$ en $(D_{Grow - Pos} \cup D_{Grow - Neg}) \cup (D_{Prune - Pos} \cup D_{Prune - Neg})$ \\
	 Rule $_{:=}$ GrowRule($D_{Grow - Pos} \cup D_{Grow - Neg}$)\\
	 Rule $_{:=}$ PruneRule($D_{Prune - Pos} \cup D_{Prune - Neg}$)\\
	 \eIf{la tasa de error de Rule en $(D_{Prune - Pos} \cup D_{Prune - Neg}) > 50\%$}{
	 	\Return RuleSet
	 }{
	 	Añadir Rule a RuleSet\\
		Borrar ejemplos cubiertos por Rule de $D$
		
	 }
}
\Return RuleSet
\end{algorithm} 

\section{Experimentación y Resultados:}
Hemos ejecutado el programa y nos han salido estos resultados:

\begin{figure}[H]
\caption{gráfico 1} 
\centering
\includegraphics[width=0.6\textwidth]{./grafica1.png}
\end{figure}

Como podemos ver según el parámetro k va en aumento, las métricas van obteniendo distintos valores importantes. Son importantes porque están altamente correlacionados. Según el \ref{figura1} gráfico 1 la medida de SSE baja según que el parámetro k aumenta mientras que la medida Silhouette aumenta mientras que el parámetro k aumenta. Esto no quiere decir que el mejor número para el parámetro k sea cuanto más grande mejor. Simplemente quiere decir que como es normal si un conjunto de datos tiene 70 instancias y hacemos 50 clusters, es muy fácil que las instancias estén muy bien repartidas ya que solamente hay otras 20 instancias en las que podríamos tener dudas.\\
\begin{figure}[H]
\caption{gráfico 2}
\label{figura1} 
\centering
\includegraphics[width=0.6\textwidth]{./grafica2.png}
\end{figure}
En cuanto al gráfico del tiempo vemos que cuanto más grande es el parámetro k el tiempo de ejecución para cada partición es mayor. Esto quiere decir, que cuantos más clusters existan, más distancias se deben de calcular entre los centroides y las instancias, por lo tanto, un mayor tiempo de ejecución. 
\section{Conclusiones:}
El algoritmo K-Means tiene una gran limitación, y es que es muy dependiente del conjunto de datos. Es un algoritmo sencillo de implementar pero pese a su simplicidad es bastante eficiente. Los algoritmos de evaluación interna SSE(p) y Silhouette son bastante completos, aunque a nuestro parecer el Silhouette es el mejor de los dos.
	
\section{Valoración Subjetiva:}
\textbf{Ieltzu}:  Ha sido una práctica bastante interesante en cuanto a programación. Al principio pensábamos que iba a ser más difícil implementar el algoritmo, pero una vez que empezamos salió todo bastante fluido. Nuestros mayores problemas fueron entender los algoritmos SSE(p) y el Silhouette. Por lo demás muy fácil. Al crear los gráficos tenemos una visión mucho mejor de como cambian los valores SSE y Silhouette según sus parámetros.\\
\textbf{Mikel}:


\textbf{Maria}:



\section*{Bibliografia}
\begin{itemize}
	\item https://es.wikipedia.org/wiki/K-means
	\item https://exceltotal.com/como-crear-un-grafico-en-excel/
\end{itemize}

\end{document}

